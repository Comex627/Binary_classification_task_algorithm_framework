{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (accuracy_score, roc_auc_score, f1_score, \n",
    "                             precision_score, recall_score, roc_curve)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "import gc\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import features_selection as fs\n",
    "\n",
    "# 设置中文字体，解决乱码问题\n",
    "plt.rcParams[\"font.family\"] = [\"SimHei\", \"WenQuanYi Micro Hei\", \"Heiti TC\"]\n",
    "sns.set(font='SimHei', font_scale=0.8)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "label = pd.read_csv('../data/train_label.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "sub = pd.read_csv('../data/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,train_y,test_x,features = fs.process_features(train, test, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机种子，保证结果可复现\n",
    "np.random.seed(42)\n",
    "\n",
    "# 假设train_x（DataFrame或数组）和train_y（Series或数组）是已有的训练数据\n",
    "# 请确保在实际使用时已经正确加载了这两个变量\n",
    "\n",
    "# 确保train_y是一维数组\n",
    "if isinstance(train_y, pd.Series):\n",
    "    train_y = train_y.values\n",
    "\n",
    "# 获取特征数量和特征名称\n",
    "if isinstance(train_x, pd.DataFrame):\n",
    "    n_features = train_x.shape[1]\n",
    "    feature_names = train_x.columns.tolist()\n",
    "else:\n",
    "    n_features = train_x.shape[1]\n",
    "    feature_names = [f'特征{i+1}' for i in range(n_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 定义多组不同的LightGBM参数配置（用于投票模型）\n",
    "def get_lgb_param_sets():\n",
    "    return [\n",
    "        # 第一组参数\n",
    "        {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'binary',\n",
    "            'metric': 'auc',\n",
    "            'learning_rate': 0.05,\n",
    "            'num_leaves': 31,\n",
    "            'max_depth': -1,\n",
    "            'feature_fraction': 0.8,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': 0,\n",
    "            'seed': 42,\n",
    "            'n_jobs': -1\n",
    "        },\n",
    "        # 第二组参数\n",
    "        {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'binary',\n",
    "            'metric': 'auc',\n",
    "            'learning_rate': 0.03,\n",
    "            'num_leaves': 63,\n",
    "            'max_depth': 8,\n",
    "            'feature_fraction': 0.7,\n",
    "            'bagging_fraction': 0.7,\n",
    "            'bagging_freq': 3,\n",
    "            'verbose': 0,\n",
    "            'seed': 43,\n",
    "            'n_jobs': -1\n",
    "        },\n",
    "        # 第三组参数\n",
    "        {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'binary',\n",
    "            'metric': 'auc',\n",
    "            'learning_rate': 0.1,\n",
    "            'num_leaves': 25,\n",
    "            'max_depth': 6,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.9,\n",
    "            'bagging_freq': 7,\n",
    "            'verbose': 0,\n",
    "            'seed': 44,\n",
    "            'n_jobs': -1\n",
    "        },\n",
    "        # 第四组参数\n",
    "        {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'binary',\n",
    "            'metric': 'auc',\n",
    "            'learning_rate': 0.05,\n",
    "            'num_leaves': 31,\n",
    "            'max_depth': -1,\n",
    "            'feature_fraction': 0.8,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'drop_rate': 0.1,\n",
    "            'verbose': 0,\n",
    "            'seed': 45,\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "将使用4个不同参数配置的LightGBM模型进行投票集成\n",
      "开始训练基模型...\n",
      "基模型 1 交叉验证AUC: 0.7252\n"
     ]
    }
   ],
   "source": [
    "# 2. 实现投票集成模型\n",
    "def voting_ensemble(X, y, n_splits=5):\n",
    "    param_sets = get_lgb_param_sets()\n",
    "    print(f\"将使用{len(param_sets)}个不同参数配置的LightGBM模型进行投票集成\")\n",
    "    \n",
    "    # 训练所有基模型\n",
    "    models = []\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    print(\"开始训练基模型...\")\n",
    "    for i, params in enumerate(param_sets, 1):\n",
    "        # 交叉验证训练单个模型\n",
    "        oof_preds = np.zeros(X.shape[0])\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "            if isinstance(X, pd.DataFrame):\n",
    "                X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            else:\n",
    "                X_train, X_val = X[train_idx], X[val_idx]\n",
    "            \n",
    "            y_train, y_val = y[train_idx], y[val_idx]\n",
    "            \n",
    "            lgb_train = lgb.Dataset(X_train, y_train)\n",
    "            lgb_val = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
    "            \n",
    "            model = lgb.train(\n",
    "                params,\n",
    "                lgb_train,\n",
    "                num_boost_round=1000,\n",
    "                valid_sets=[lgb_train, lgb_val],\n",
    "                early_stopping_rounds=50,\n",
    "                verbose_eval=0\n",
    "            )\n",
    "            \n",
    "            oof_preds[val_idx] = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "            \n",
    "            # 只保留最后一折的模型用于最终预测\n",
    "            if fold == kf.n_splits - 1:\n",
    "                models.append(model)\n",
    "        \n",
    "        # 评估该模型的OOF性能\n",
    "        auc = roc_auc_score(y, oof_preds)\n",
    "        print(f\"基模型 {i} 交叉验证AUC: {auc:.4f}\")\n",
    "    \n",
    "    return models, param_sets\n",
    "\n",
    "# 3. 训练投票集成模型\n",
    "models, param_sets = voting_ensemble(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 特征重要性可视化\n",
    "def plot_feature_importance(models, feature_names, top_n=30, figsize=(15, 10)):\n",
    "    # 基模型特征重要性比较\n",
    "    plt.figure(figsize=figsize)\n",
    "    all_importance = []\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        importance = model.feature_importance(importance_type='gain')\n",
    "        feat_imp = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': importance,\n",
    "            'model': f'模型 {i+1}'\n",
    "        })\n",
    "        all_importance.append(feat_imp)\n",
    "    \n",
    "    all_importance = pd.concat(all_importance)\n",
    "    top_features = all_importance.groupby('feature')['importance'].mean().nlargest(top_n).index\n",
    "    top_imp = all_importance[all_importance['feature'].isin(top_features)]\n",
    "    \n",
    "    sns.barplot(x='importance', y='feature', hue='model', data=top_imp)\n",
    "    plt.title(f'各模型特征重要性对比（前{top_n}特征）', fontsize=15)\n",
    "    plt.xlabel('重要性 (Gain)', fontsize=12)\n",
    "    plt.ylabel('特征', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 平均特征重要性\n",
    "    plt.figure(figsize=figsize)\n",
    "    mean_imp = all_importance.groupby('feature')['importance'].mean().reset_index()\n",
    "    mean_imp = mean_imp.sort_values('importance', ascending=False).head(top_n)\n",
    "    sns.barplot(x='importance', y='feature', data=mean_imp)\n",
    "    plt.title(f'平均特征重要性（前{top_n}特征）', fontsize=15)\n",
    "    plt.xlabel('平均重要性 (Gain)', fontsize=12)\n",
    "    plt.ylabel('特征', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_feature_importance(models, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 投票预测函数\n",
    "def voting_predict(models, X, voting_type='soft'):\n",
    "    \"\"\"\n",
    "    投票预测\n",
    "    voting_type: 'soft'为概率加权平均, 'hard'为多数表决\n",
    "    \"\"\"\n",
    "    if voting_type == 'hard':\n",
    "        # 硬投票：取多数类\n",
    "        predictions = []\n",
    "        for model in models:\n",
    "            pred_proba = model.predict(X, num_iteration=model.best_iteration)\n",
    "            predictions.append((pred_proba >= 0.5).astype(int))\n",
    "        \n",
    "        predictions = np.array(predictions).T\n",
    "        final_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=1, arr=predictions)\n",
    "        return final_pred\n",
    "    else:\n",
    "        # 软投票：概率平均值\n",
    "        all_preds = []\n",
    "        for model in models:\n",
    "            pred = model.predict(X, num_iteration=model.best_iteration)\n",
    "            all_preds.append(pred)\n",
    "        \n",
    "        return np.mean(all_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 模型评估与可视化\n",
    "def calculate_metrics(y_true, y_pred_proba):\n",
    "    auc = roc_auc_score(y_true, y_pred_proba)\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
    "    ks = max(tpr - fpr)\n",
    "    \n",
    "    thresholds = np.arange(0.1, 1.0, 0.1)\n",
    "    f1_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "        f1_scores.append(f1_score(y_true, y_pred))\n",
    "        precision_scores.append(precision_score(y_true, y_pred))\n",
    "        recall_scores.append(recall_score(y_true, y_pred))\n",
    "    \n",
    "    best_f1_idx = np.argmax(f1_scores)\n",
    "    best_f1 = f1_scores[best_f1_idx]\n",
    "    best_threshold = thresholds[best_f1_idx]\n",
    "    \n",
    "    return {\n",
    "        'auc': auc, 'ks': ks, 'best_f1': best_f1, \n",
    "        'best_threshold': best_threshold, 'thresholds': thresholds,\n",
    "        'f1_scores': f1_scores, 'precision_scores': precision_scores,\n",
    "        'recall_scores': recall_scores, 'fpr': fpr, 'tpr': tpr\n",
    "    }\n",
    "\n",
    "def plot_metrics(metrics, figsize=(15, 10)):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=figsize)\n",
    "    fig.suptitle('模型评估指标', fontsize=16)\n",
    "    \n",
    "    # 1. 关键指标值\n",
    "    ax1 = axes[0, 0]\n",
    "    metrics_text = (f\"AUC: {metrics['auc']:.4f}\\n\"\n",
    "                   f\"KS: {metrics['ks']:.4f}\\n\"\n",
    "                   f\"最佳F1: {metrics['best_f1']:.4f}\\n\"\n",
    "                   f\"最佳阈值: {metrics['best_threshold']:.2f}\")\n",
    "    ax1.text(0.5, 0.5, metrics_text, fontsize=14, ha='center', va='center')\n",
    "    ax1.set_title('关键指标值')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # 2. ROC曲线\n",
    "    ax2 = axes[0, 1]\n",
    "    ax2.plot(metrics['fpr'], metrics['tpr'], label=f'ROC曲线 (AUC = {metrics[\"auc\"]:.4f})')\n",
    "    ax2.plot([0, 1], [0, 1], 'k--')\n",
    "    ax2.set_xlabel('假正例率 (FPR)')\n",
    "    ax2.set_ylabel('真正例率 (TPR)')\n",
    "    ax2.set_title('ROC曲线')\n",
    "    ax2.legend()\n",
    "    \n",
    "    # 3. KS曲线\n",
    "    ax3 = axes[1, 0]\n",
    "    ax3.plot(metrics['fpr'], label='FPR')\n",
    "    ax3.plot(metrics['tpr'], label='TPR')\n",
    "    ax3.plot(metrics['tpr'] - metrics['fpr'], label=f'KS ({metrics[\"ks\"]:.4f})')\n",
    "    ax3.set_xlabel('阈值位置')\n",
    "    ax3.set_ylabel('比例')\n",
    "    ax3.set_title('KS曲线')\n",
    "    ax3.legend()\n",
    "    \n",
    "    # 4. 阈值对指标的影响\n",
    "    ax4 = axes[1, 1]\n",
    "    ax4.plot(metrics['thresholds'], metrics['f1_scores'], label='F1分数')\n",
    "    ax4.plot(metrics['thresholds'], metrics['precision_scores'], label='精确率')\n",
    "    ax4.plot(metrics['thresholds'], metrics['recall_scores'], label='召回率')\n",
    "    ax4.axvline(x=metrics['best_threshold'], color='r', linestyle='--', \n",
    "                label=f'最佳阈值: {metrics[\"best_threshold\"]:.2f}')\n",
    "    ax4.set_xlabel('阈值')\n",
    "    ax4.set_ylabel('分数')\n",
    "    ax4.set_title('不同阈值下的分类指标')\n",
    "    ax4.legend()\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n",
    "\n",
    "# 交叉验证评估投票模型\n",
    "print(\"\\n交叉验证评估投票模型...\")\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "final_auc_scores = []\n",
    "final_ks_scores = []\n",
    "final_f1_scores = []\n",
    "\n",
    "# 保存最后一折结果用于可视化\n",
    "y_val = None\n",
    "y_pred_proba = None\n",
    "fold_metrics = None\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(train_x, train_y)):\n",
    "    if isinstance(train_x, pd.DataFrame):\n",
    "        X_val = train_x.iloc[val_idx]\n",
    "    else:\n",
    "        X_val = train_x[val_idx]\n",
    "    \n",
    "    # 投票预测\n",
    "    val_preds = voting_predict(models, X_val)\n",
    "    \n",
    "    # 计算指标\n",
    "    metrics = calculate_metrics(train_y[val_idx], val_preds)\n",
    "    \n",
    "    final_auc_scores.append(metrics['auc'])\n",
    "    final_ks_scores.append(metrics['ks'])\n",
    "    final_f1_scores.append(metrics['best_f1'])\n",
    "    \n",
    "    # 保存最后一折结果\n",
    "    if fold == kf.n_splits - 1:\n",
    "        y_val = train_y[val_idx]\n",
    "        y_pred_proba = val_preds\n",
    "        fold_metrics = metrics\n",
    "\n",
    "print(f\"投票模型平均AUC: {np.mean(final_auc_scores):.4f} ± {np.std(final_auc_scores):.4f}\")\n",
    "print(f\"投票模型平均KS: {np.mean(final_ks_scores):.4f} ± {np.std(final_ks_scores):.4f}\")\n",
    "print(f\"投票模型平均最佳F1: {np.mean(final_f1_scores):.4f} ± {np.std(final_f1_scores):.4f}\")\n",
    "\n",
    "# 绘制评估指标可视化\n",
    "plot_metrics(fold_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 7. 基模型性能对比可视化\n",
    "def plot_base_model_comparison(models, X_val, y_val, figsize=(12, 8)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # 各模型ROC曲线对比\n",
    "    for i, model in enumerate(models):\n",
    "        y_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "        fpr, tpr, _ = roc_curve(y_val, y_pred)\n",
    "        auc = roc_auc_score(y_val, y_pred)\n",
    "        plt.plot(fpr, tpr, label=f'模型 {i+1} (AUC = {auc:.4f})')\n",
    "    \n",
    "    # 投票模型ROC曲线\n",
    "    voting_pred = voting_predict(models, X_val)\n",
    "    fpr_voting, tpr_voting, _ = roc_curve(y_val, voting_pred)\n",
    "    auc_voting = roc_auc_score(y_val, voting_pred)\n",
    "    plt.plot(fpr_voting, tpr_voting, 'k-', linewidth=2, \n",
    "             label=f'投票模型 (AUC = {auc_voting:.4f})')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('假正例率 (FPR)')\n",
    "    plt.ylabel('真正例率 (TPR)')\n",
    "    plt.title('基模型与投票模型ROC曲线对比')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 绘制基模型与投票模型对比\n",
    "plot_base_model_comparison(models, X_val, y_val)\n",
    "\n",
    "# 8. 保存模型\n",
    "print(\"\\n保存模型...\")\n",
    "voting_model = {\n",
    "    'base_models': models,\n",
    "    'param_sets': param_sets\n",
    "}\n",
    "\n",
    "with open('./models/voting_ensemble_model.pkl', 'wb') as f:\n",
    "    pickle.dump(voting_model, f)\n",
    "\n",
    "print(\"模型已保存为 voting_ensemble_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. 加载模型并预测\n",
    "def predict_with_voting_model(model_path, X, voting_type='soft'):\n",
    "    with open(model_path, 'rb') as f:\n",
    "        voting_model = pickle.load(f)\n",
    "    \n",
    "    base_models = voting_model['base_models']\n",
    "    return voting_predict(base_models, X, voting_type)\n",
    "\n",
    "# 生成测试集预测结果\n",
    "test_predictions = predict_with_voting_model('./models/voting_ensemble_model.pkl', test_x)\n",
    "print(\"\\n测试集预测结果示例:\", test_predictions[:10])\n",
    "\n",
    "# 生成提交文件\n",
    "sub['label'] = test_predictions\n",
    "sub.to_csv('./sub/voting_ensemble_submission.csv', index=False)\n",
    "print(\"提交文件已保存为 voting_ensemble_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
